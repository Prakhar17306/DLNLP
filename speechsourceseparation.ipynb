{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install musdb\n# !pip install librosa\n# !pip install museval","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:33:54.521986Z","iopub.execute_input":"2023-05-01T22:33:54.522932Z","iopub.status.idle":"2023-05-01T22:34:28.133673Z","shell.execute_reply.started":"2023-05-01T22:33:54.522897Z","shell.execute_reply":"2023-05-01T22:34:28.132436Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting musdb\n  Downloading musdb-0.4.0-py2.py3-none-any.whl (29 kB)\nRequirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.7/site-packages (from musdb) (1.21.6)\nCollecting stempeg>=0.2.3\n  Downloading stempeg-0.2.3-py3-none-any.whl (963 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pyaml in /opt/conda/lib/python3.7/site-packages (from musdb) (21.10.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from musdb) (4.64.1)\nCollecting ffmpeg-python>=0.2.0\n  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from pyaml->musdb) (6.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (0.18.3)\nInstalling collected packages: ffmpeg-python, stempeg, musdb\nSuccessfully installed ffmpeg-python-0.2.0 musdb-0.4.0 stempeg-0.2.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: librosa in /opt/conda/lib/python3.7/site-packages (0.10.0.post2)\nCollecting soundfile>=0.12.1\n  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pooch<1.7,>=1.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.6.0)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.0.2)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.7.3)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.2)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.3.4)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.56.4)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.21.6)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.2.0)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.7/site-packages (from librosa) (3.0.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from librosa) (4.4.0)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.0.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.51.0->librosa) (59.8.0)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.51.0->librosa) (0.39.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from numba>=0.51.0->librosa) (4.11.4)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from pooch<1.7,>=1.0->librosa) (23.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from pooch<1.7,>=1.0->librosa) (2.28.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->numba>=0.51.0->librosa) (3.11.0)\nInstalling collected packages: soundfile\n  Attempting uninstall: soundfile\n    Found existing installation: soundfile 0.11.0\n    Uninstalling soundfile-0.11.0:\n      Successfully uninstalled soundfile-0.11.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nwfdb 4.1.0 requires SoundFile<0.12.0,>=0.10.0, but you have soundfile 0.12.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed soundfile-0.12.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport random\nimport math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport musdb\n# import librosa\nfrom tqdm.auto import tqdm\nfrom torchaudio.transforms import Spectrogram, MelSpectrogram, InverseSpectrogram","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:34:28.138988Z","iopub.execute_input":"2023-05-01T22:34:28.139349Z","iopub.status.idle":"2023-05-01T22:34:30.583980Z","shell.execute_reply.started":"2023-05-01T22:34:28.139312Z","shell.execute_reply":"2023-05-01T22:34:30.582959Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class MUSDB18Dataset(Dataset):\n    def __init__(self, musdb18_root, subset=\"train\", split = \"train\", sr=44100, duration=2.0, seed = 42):\n        self.sr = sr\n        self.duration = duration\n        self.seed = seed\n        if(subset == 'test'):\n            self.musdb18 = musdb.DB(root = musdb18_root, subsets=subset)\n            print(f\"Number of Testing Samples: {len(self.musdb18)}\")\n        else:\n            self.musdb18 = musdb.DB(root = musdb18_root, subsets = subset, split = split)\n            if split == \"train\":\n                print(f\"Number of Training Samples: {len(self.musdb18)}\")\n            else:\n                print(f\"Number of Validation Samples: {len(self.musdb18)}\")\n        \n    def __getitem__(self, index):\n        random.seed(self.seed)\n        track = self.musdb18.tracks[index]\n        track.chunk_duration = self.duration\n        track.chunk_start = random.uniform(0, track.duration - track.chunk_duration)\n        \n        # Load the mixture waveform\n        audio = track.audio.T\n        audio = audio.mean(axis = 0, keepdims = True)\n        audio_tensor = torch.from_numpy(audio).float()\n        \n        # Load the target waveform (vocals)\n        vocals = track.targets[\"vocals\"].audio.T\n        vocals = vocals.mean(axis = 0, keepdims = True)\n        others = track.targets[\"accompaniment\"].audio.T\n        others = others.mean(axis = 0, keepdims = True)\n        \n        vocals_tensor = torch.from_numpy(np.concatenate((vocals, others), axis = 0)).float()\n        \n        return audio_tensor, vocals_tensor\n\n    def __len__(self):\n        return len(self.musdb18.tracks)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:34:30.585487Z","iopub.execute_input":"2023-05-01T22:34:30.586159Z","iopub.status.idle":"2023-05-01T22:34:30.598281Z","shell.execute_reply.started":"2023-05-01T22:34:30.586120Z","shell.execute_reply":"2023-05-01T22:34:30.597142Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_musdb18_dataloaders(root, batch_size=8, num_workers=0, seed = 42):\n    train_set = MUSDB18Dataset(root, subset=\"train\")\n    val_set = MUSDB18Dataset(root, subset=\"train\", split = 'valid')\n    test_set = MUSDB18Dataset(root, subset=\"test\")\n\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    return train_loader, val_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:34:30.600046Z","iopub.execute_input":"2023-05-01T22:34:30.600429Z","iopub.status.idle":"2023-05-01T22:34:30.612363Z","shell.execute_reply.started":"2023-05-01T22:34:30.600391Z","shell.execute_reply":"2023-05-01T22:34:30.611135Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class TransformerModel(nn.Module):\n    def __init__(self, d_model = 512, num_heads = 8, num_layers = 6, dropout = 0.1):\n        super().__init__()\n        \n        # input embedding layer\n        self.input_embed = nn.Linear(101, d_model)\n\n        # transformer encoder layers\n        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads, dropout=dropout)\n        self.encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n        \n        decoder_layers = nn.TransformerDecoderLayer(d_model=d_model, nhead = num_heads, dropout=dropout)\n        self.decoder = nn.TransformerDecoder(decoder_layers, num_layers = num_layers//2)\n                \n        # output embedding layer\n        self.output_embed = nn.Linear(d_model, 202)\n        \n        self.transform = Spectrogram(n_fft = 200)\n        self.invtransform = InverseSpectrogram(n_fft = 200)\n        \n    def forward(self, x):\n        \n        length = x.size(-1)\n        \n        x = self.transform(x)\n        x = x.permute(3, 0, 1, 2)\n        x = x.reshape(x.size(0), -1, x.size(-1))\n        \n        # apply input embedding layer\n        x = self.input_embed(x)\n        \n        # apply transformer encoder layers\n        x = self.encoder(x)\n        memory = x\n        \n        # apply transformer decoder layers\n        x = self.decoder(x, memory)\n        \n        # apply output embedding layer\n        x = self.output_embed(x)\n        \n        # reshape x back to (batch_size, num_channels, num_frames, num_bins)\n        x = x.reshape(x.size(1), 2, -1, x.size(0))\n        \n        y = self.invtransform(x.type(torch.complex64), length)\n        \n        return y","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:40.492489Z","iopub.execute_input":"2023-05-01T22:42:40.493040Z","iopub.status.idle":"2023-05-01T22:42:40.506295Z","shell.execute_reply.started":"2023-05-01T22:42:40.493002Z","shell.execute_reply":"2023-05-01T22:42:40.505186Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloader, optimizer, loss_fn):\n    model.train()\n    total_loss = 0\n\n    for i, (audio, vocals) in enumerate(dataloader):\n        # move data to GPU if available\n        if torch.cuda.is_available():\n            audio = audio.cuda()\n            vocals = vocals.cuda()\n\n        # forward pass\n        prediction = model(audio)\n        loss = loss_fn(prediction, vocals)\n\n        # backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # update total loss\n        total_loss += loss.item()\n\n    # compute average loss\n    avg_loss = total_loss / len(dataloader)\n\n    return avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:41.225174Z","iopub.execute_input":"2023-05-01T22:42:41.226243Z","iopub.status.idle":"2023-05-01T22:42:41.234245Z","shell.execute_reply.started":"2023-05-01T22:42:41.226196Z","shell.execute_reply":"2023-05-01T22:42:41.232678Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloader, loss_fn):\n    model.eval()\n    total_loss = 0\n\n    with torch.no_grad():\n        for i, (audio, vocals) in enumerate(dataloader):\n            # move data to GPU if available\n            if torch.cuda.is_available():\n                audio = audio.cuda()\n                vocals = vocals.cuda()\n\n            # forward pass\n            prediction = model(audio)\n            loss = loss_fn(prediction, vocals)\n\n            # update total loss\n            total_loss += loss.item()\n\n    # compute average loss\n    avg_loss = total_loss / len(dataloader)\n\n    return avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:41.377386Z","iopub.execute_input":"2023-05-01T22:42:41.378195Z","iopub.status.idle":"2023-05-01T22:42:41.385377Z","shell.execute_reply.started":"2023-05-01T22:42:41.378154Z","shell.execute_reply":"2023-05-01T22:42:41.384283Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def fit(model, optimizer, loss_fn, num_epochs, train_dataloader, val_dataloader):\n    for epoch in tqdm(range(num_epochs)):\n        # train model for one epoch\n        train_loss = train(model, train_dataloader, optimizer, loss_fn)\n        print(f'Epoch {epoch + 1} - Train loss: {train_loss:.4f}')\n\n        # evaluate model on validation data\n        val_loss = validate(model, val_dataloader, loss_fn)\n        print(f'Epoch {epoch + 1} - Val loss: {val_loss:.4f}')\n        print(\"---------------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:41.588112Z","iopub.execute_input":"2023-05-01T22:42:41.588419Z","iopub.status.idle":"2023-05-01T22:42:41.594619Z","shell.execute_reply.started":"2023-05-01T22:42:41.588391Z","shell.execute_reply":"2023-05-01T22:42:41.593477Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def calculate_sdr(predicted_output, ground_truth):\n    \"\"\"\n    Calculates the Signal-to-Distortion Ratio (SDR) metric between a predicted output and its corresponding ground truth.\n\n    Args:\n    predicted_output: A numpy array of shape (number of channels, number of frames, number of bins).\n    ground_truth: A numpy array of shape (number of channels, number of frames, number of bins).\n\n    Returns:\n    sdr: A scalar representing the SDR value between predicted_output and ground_truth.\n    \"\"\"\n    eps = np.finfo(np.float32).eps  # To avoid division by zero errors\n    num_channels = predicted_output.shape[0]\n    sdr_sum = 0\n    \n#     print(predicted_output.shape, ground_truth.shape)\n    \n    for c in range(num_channels):\n        # Compute the power of the true source signal\n        true_source_power = np.sum(ground_truth[c]**2)\n\n        # Compute the scalar product between true source signal and predicted signal\n        true_pred_scalar = np.sum(ground_truth[c] * predicted_output[c])\n\n        # Compute the SDR for this channel\n        sdr = 10 * np.log10(true_source_power / (np.sum(ground_truth[c]**2) - true_pred_scalar + eps) + eps)\n        if not math.isnan(sdr):\n            sdr_sum += sdr\n\n    # Compute the average SDR across all channels\n    sdr = sdr_sum / num_channels\n\n    return -sdr","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:41.768421Z","iopub.execute_input":"2023-05-01T22:42:41.768720Z","iopub.status.idle":"2023-05-01T22:42:41.775862Z","shell.execute_reply.started":"2023-05-01T22:42:41.768684Z","shell.execute_reply":"2023-05-01T22:42:41.774823Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def test(model, dataloader):\n    model.eval()\n    all_targets = []\n    all_predictions = []\n    sdr = 0\n    count = 0\n    with torch.no_grad():\n        for i, (audio, vocals) in tqdm(enumerate(dataloader)):\n            # move data to GPU if available\n            if torch.cuda.is_available():\n                audio = audio.cuda()\n                vocals = vocals.cuda()\n\n            # forward pass\n            prediction = model(audio)\n            \n            # convert predictions and ground truth to numpy arrays\n            prediction = prediction.cpu().numpy()\n            vocals = vocals.cpu().numpy()\n            \n            for i in range(prediction.shape[0]):\n                pred = prediction[i,:,:]\n                targ = vocals[i,:,:]\n                sdr += calculate_sdr(pred, targ)\n                count += 1\n    mean_sdr = sdr/count\n    return mean_sdr","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:41.912202Z","iopub.execute_input":"2023-05-01T22:42:41.912804Z","iopub.status.idle":"2023-05-01T22:42:41.920803Z","shell.execute_reply.started":"2023-05-01T22:42:41.912761Z","shell.execute_reply":"2023-05-01T22:42:41.919796Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"root = \"/kaggle/input/musdb18/musdb18\"\ntrain_loader, val_loader, test_loader = get_musdb18_dataloaders(root, batch_size = 2)\n# for x, y in val_loader:\n#     print(x.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:42.063419Z","iopub.execute_input":"2023-05-01T22:42:42.063700Z","iopub.status.idle":"2023-05-01T22:42:59.470432Z","shell.execute_reply.started":"2023-05-01T22:42:42.063674Z","shell.execute_reply":"2023-05-01T22:42:59.469136Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Number of Training Samples: 87\nNumber of Validation Samples: 13\nNumber of Testing Samples: 50\n","output_type":"stream"}]},{"cell_type":"code","source":"# define model and optimizer\nmodel = TransformerModel(num_heads = 8, num_layers = 6)\n# model = PretrainedTransformer(output_size=257, num_heads = 8, num_layers = 6)\nif torch.cuda.is_available():\n    model = model.cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# define loss function\nloss_fn = nn.MSELoss()\n\n# fit(model, optimizer, loss_fn, 250, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:59.473721Z","iopub.execute_input":"2023-05-01T22:42:59.474559Z","iopub.status.idle":"2023-05-01T22:42:59.678217Z","shell.execute_reply.started":"2023-05-01T22:42:59.474523Z","shell.execute_reply":"2023-05-01T22:42:59.677143Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# print(f\"Training MSE: {validate(model, train_loader, loss_fn)}\")\n# print(f\"Validation MSE: {validate(model, val_loader, loss_fn)}\")\n# print(f\"Testing MSE: {validate(model, test_loader, loss_fn)}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:59.679689Z","iopub.execute_input":"2023-05-01T22:42:59.680084Z","iopub.status.idle":"2023-05-01T22:42:59.687414Z","shell.execute_reply.started":"2023-05-01T22:42:59.680045Z","shell.execute_reply":"2023-05-01T22:42:59.686391Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import warnings\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)    \n    print(f\"Training SDR: {test(model, train_loader)}\")\n    print(f\"Validation SDR: {test(model, val_loader)}\")\n    print(f\"Testing SDR: {test(model, test_loader)}\")","metadata":{},"execution_count":null,"outputs":[]}]}