{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install musdb\n# !pip install librosa\n# !pip install museval","metadata":{"execution":{"iopub.status.busy":"2023-05-02T14:54:03.777331Z","iopub.execute_input":"2023-05-02T14:54:03.777742Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x734a2eba6320>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/musdb/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x734a2eba43d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/musdb/\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport random\nimport math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport musdb\n# import librosa\nfrom tqdm.auto import tqdm\nfrom torchaudio.transforms import Spectrogram, MelSpectrogram, InverseSpectrogram","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:34:28.138988Z","iopub.execute_input":"2023-05-01T22:34:28.139349Z","iopub.status.idle":"2023-05-01T22:34:30.583980Z","shell.execute_reply.started":"2023-05-01T22:34:28.139312Z","shell.execute_reply":"2023-05-01T22:34:30.582959Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class MUSDB18Dataset(Dataset):\n    def __init__(self, musdb18_root, subset=\"train\", split = \"train\", sr=44100, duration=2.0, seed = 42):\n        self.sr = sr\n        self.duration = duration\n        self.seed = seed\n        if(subset == 'test'):\n            self.musdb18 = musdb.DB(root = musdb18_root, subsets=subset)\n            print(f\"Number of Testing Samples: {len(self.musdb18)}\")\n        else:\n            self.musdb18 = musdb.DB(root = musdb18_root, subsets = subset, split = split)\n            if split == \"train\":\n                print(f\"Number of Training Samples: {len(self.musdb18)}\")\n            else:\n                print(f\"Number of Validation Samples: {len(self.musdb18)}\")\n        \n    def __getitem__(self, index):\n        random.seed(self.seed)\n        track = self.musdb18.tracks[index]\n        track.chunk_duration = self.duration\n        track.chunk_start = random.uniform(0, track.duration - track.chunk_duration)\n        \n        # Load the mixture waveform\n        audio = track.audio.T\n        audio = audio.mean(axis = 0, keepdims = True)\n        audio_tensor = torch.from_numpy(audio).float()\n        \n        # Load the target waveform (vocals)\n        vocals = track.targets[\"vocals\"].audio.T\n        vocals = vocals.mean(axis = 0, keepdims = True)\n        others = track.targets[\"accompaniment\"].audio.T\n        others = others.mean(axis = 0, keepdims = True)\n        \n        vocals_tensor = torch.from_numpy(np.concatenate((vocals, others), axis = 0)).float()\n        \n        return audio_tensor, vocals_tensor\n\n    def __len__(self):\n        return len(self.musdb18.tracks)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:34:30.585487Z","iopub.execute_input":"2023-05-01T22:34:30.586159Z","iopub.status.idle":"2023-05-01T22:34:30.598281Z","shell.execute_reply.started":"2023-05-01T22:34:30.586120Z","shell.execute_reply":"2023-05-01T22:34:30.597142Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_musdb18_dataloaders(root, batch_size=8, num_workers=0, seed = 42):\n    train_set = MUSDB18Dataset(root, subset=\"train\")\n    val_set = MUSDB18Dataset(root, subset=\"train\", split = 'valid')\n    test_set = MUSDB18Dataset(root, subset=\"test\")\n\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    return train_loader, val_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:34:30.600046Z","iopub.execute_input":"2023-05-01T22:34:30.600429Z","iopub.status.idle":"2023-05-01T22:34:30.612363Z","shell.execute_reply.started":"2023-05-01T22:34:30.600391Z","shell.execute_reply":"2023-05-01T22:34:30.611135Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class TransformerModel(nn.Module):\n    def __init__(self, d_model = 512, num_heads = 8, num_layers = 6, dropout = 0.1):\n        super().__init__()\n        \n        # input embedding layer\n        self.input_embed = nn.Linear(101, d_model)\n\n        # transformer encoder layers\n        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads, dropout=dropout)\n        self.encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n        \n        decoder_layers = nn.TransformerDecoderLayer(d_model=d_model, nhead = num_heads, dropout=dropout)\n        self.decoder = nn.TransformerDecoder(decoder_layers, num_layers = num_layers//2)\n                \n        # output embedding layer\n        self.output_embed = nn.Linear(d_model, 202)\n        \n        self.transform = Spectrogram(n_fft = 200)\n        self.invtransform = InverseSpectrogram(n_fft = 200)\n        \n    def forward(self, x):\n        \n        length = x.size(-1)\n        \n        x = self.transform(x)\n        x = x.permute(3, 0, 1, 2)\n        x = x.reshape(x.size(0), -1, x.size(-1))\n        \n        # apply input embedding layer\n        x = self.input_embed(x)\n        \n        # apply transformer encoder layers\n        x = self.encoder(x)\n        memory = x\n        \n        # apply transformer decoder layers\n        x = self.decoder(x, memory)\n        \n        # apply output embedding layer\n        x = self.output_embed(x)\n        \n        # reshape x back to (batch_size, num_channels, num_frames, num_bins)\n        x = x.reshape(x.size(1), 2, -1, x.size(0))\n        \n        y = self.invtransform(x.type(torch.complex64), length)\n        \n        return y","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:40.492489Z","iopub.execute_input":"2023-05-01T22:42:40.493040Z","iopub.status.idle":"2023-05-01T22:42:40.506295Z","shell.execute_reply.started":"2023-05-01T22:42:40.493002Z","shell.execute_reply":"2023-05-01T22:42:40.505186Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloader, optimizer, loss_fn):\n    model.train()\n    total_loss = 0\n\n    for i, (audio, vocals) in enumerate(dataloader):\n        # move data to GPU if available\n        if torch.cuda.is_available():\n            audio = audio.cuda()\n            vocals = vocals.cuda()\n\n        # forward pass\n        prediction = model(audio)\n        loss = loss_fn(prediction, vocals)\n\n        # backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # update total loss\n        total_loss += loss.item()\n\n    # compute average loss\n    avg_loss = total_loss / len(dataloader)\n\n    return avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:41.225174Z","iopub.execute_input":"2023-05-01T22:42:41.226243Z","iopub.status.idle":"2023-05-01T22:42:41.234245Z","shell.execute_reply.started":"2023-05-01T22:42:41.226196Z","shell.execute_reply":"2023-05-01T22:42:41.232678Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloader, loss_fn):\n    model.eval()\n    total_loss = 0\n\n    with torch.no_grad():\n        for i, (audio, vocals) in enumerate(dataloader):\n            # move data to GPU if available\n            if torch.cuda.is_available():\n                audio = audio.cuda()\n                vocals = vocals.cuda()\n\n            # forward pass\n            prediction = model(audio)\n            loss = loss_fn(prediction, vocals)\n\n            # update total loss\n            total_loss += loss.item()\n\n    # compute average loss\n    avg_loss = total_loss / len(dataloader)\n\n    return avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:41.377386Z","iopub.execute_input":"2023-05-01T22:42:41.378195Z","iopub.status.idle":"2023-05-01T22:42:41.385377Z","shell.execute_reply.started":"2023-05-01T22:42:41.378154Z","shell.execute_reply":"2023-05-01T22:42:41.384283Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def fit(model, optimizer, loss_fn, num_epochs, train_dataloader, val_dataloader):\n    for epoch in tqdm(range(num_epochs)):\n        # train model for one epoch\n        train_loss = train(model, train_dataloader, optimizer, loss_fn)\n        print(f'Epoch {epoch + 1} - Train loss: {train_loss:.4f}')\n\n        # evaluate model on validation data\n        val_loss = validate(model, val_dataloader, loss_fn)\n        print(f'Epoch {epoch + 1} - Val loss: {val_loss:.4f}')\n        print(\"---------------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:41.588112Z","iopub.execute_input":"2023-05-01T22:42:41.588419Z","iopub.status.idle":"2023-05-01T22:42:41.594619Z","shell.execute_reply.started":"2023-05-01T22:42:41.588391Z","shell.execute_reply":"2023-05-01T22:42:41.593477Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def calculate_sdr(predicted_output, ground_truth):\n    \"\"\"\n    Calculates the Signal-to-Distortion Ratio (SDR) metric between a predicted output and its corresponding ground truth.\n\n    Args:\n    predicted_output: A numpy array of shape (number of channels, number of frames, number of bins).\n    ground_truth: A numpy array of shape (number of channels, number of frames, number of bins).\n\n    Returns:\n    sdr: A scalar representing the SDR value between predicted_output and ground_truth.\n    \"\"\"\n    eps = np.finfo(np.float32).eps  # To avoid division by zero errors\n    num_channels = predicted_output.shape[0]\n    sdr_sum = 0\n    \n#     print(predicted_output.shape, ground_truth.shape)\n    \n    for c in range(num_channels):\n        # Compute the power of the true source signal\n        true_source_power = np.sum(ground_truth[c]**2)\n\n        # Compute the scalar product between true source signal and predicted signal\n        true_pred_scalar = np.sum(ground_truth[c] * predicted_output[c])\n\n        # Compute the SDR for this channel\n        sdr = 10 * np.log10(true_source_power / (np.sum(ground_truth[c]**2) - true_pred_scalar + eps) + eps)\n        if not math.isnan(sdr):\n            sdr_sum += sdr\n\n    # Compute the average SDR across all channels\n    sdr = sdr_sum / num_channels\n\n    return -sdr","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:41.768421Z","iopub.execute_input":"2023-05-01T22:42:41.768720Z","iopub.status.idle":"2023-05-01T22:42:41.775862Z","shell.execute_reply.started":"2023-05-01T22:42:41.768684Z","shell.execute_reply":"2023-05-01T22:42:41.774823Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def test(model, dataloader):\n    model.eval()\n    all_targets = []\n    all_predictions = []\n    sdr = 0\n    count = 0\n    with torch.no_grad():\n        for i, (audio, vocals) in tqdm(enumerate(dataloader)):\n            # move data to GPU if available\n            if torch.cuda.is_available():\n                audio = audio.cuda()\n                vocals = vocals.cuda()\n\n            # forward pass\n            prediction = model(audio)\n            \n            # convert predictions and ground truth to numpy arrays\n            prediction = prediction.cpu().numpy()\n            vocals = vocals.cpu().numpy()\n            \n            for i in range(prediction.shape[0]):\n                pred = prediction[i,:,:]\n                targ = vocals[i,:,:]\n                sdr += calculate_sdr(pred, targ)\n                count += 1\n    mean_sdr = sdr/count\n    return mean_sdr","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:41.912202Z","iopub.execute_input":"2023-05-01T22:42:41.912804Z","iopub.status.idle":"2023-05-01T22:42:41.920803Z","shell.execute_reply.started":"2023-05-01T22:42:41.912761Z","shell.execute_reply":"2023-05-01T22:42:41.919796Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"root = \"/kaggle/input/musdb18/musdb18\"\ntrain_loader, val_loader, test_loader = get_musdb18_dataloaders(root, batch_size = 2)\n# for x, y in val_loader:\n#     print(x.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:42.063419Z","iopub.execute_input":"2023-05-01T22:42:42.063700Z","iopub.status.idle":"2023-05-01T22:42:59.470432Z","shell.execute_reply.started":"2023-05-01T22:42:42.063674Z","shell.execute_reply":"2023-05-01T22:42:59.469136Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Number of Training Samples: 87\nNumber of Validation Samples: 13\nNumber of Testing Samples: 50\n","output_type":"stream"}]},{"cell_type":"code","source":"# define model and optimizer\nmodel = TransformerModel(num_heads = 8, num_layers = 6)\n# model = PretrainedTransformer(output_size=257, num_heads = 8, num_layers = 6)\nif torch.cuda.is_available():\n    model = model.cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# define loss function\nloss_fn = nn.MSELoss()\n\nfit(model, optimizer, loss_fn, 250, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:59.473721Z","iopub.execute_input":"2023-05-01T22:42:59.474559Z","iopub.status.idle":"2023-05-01T22:42:59.678217Z","shell.execute_reply.started":"2023-05-01T22:42:59.474523Z","shell.execute_reply":"2023-05-01T22:42:59.677143Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"print(f\"Training MSE: {validate(model, train_loader, loss_fn)}\")\nprint(f\"Validation MSE: {validate(model, val_loader, loss_fn)}\")\nprint(f\"Testing MSE: {validate(model, test_loader, loss_fn)}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:42:59.679689Z","iopub.execute_input":"2023-05-01T22:42:59.680084Z","iopub.status.idle":"2023-05-01T22:42:59.687414Z","shell.execute_reply.started":"2023-05-01T22:42:59.680045Z","shell.execute_reply":"2023-05-01T22:42:59.686391Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import warnings\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)    \n    print(f\"Training SDR: {test(model, train_loader)}\")\n    print(f\"Validation SDR: {test(model, val_loader)}\")\n    print(f\"Testing SDR: {test(model, test_loader)}\")","metadata":{},"execution_count":null,"outputs":[]}]}